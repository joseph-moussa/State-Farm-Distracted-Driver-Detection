{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c13058d",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16b4df",
   "metadata": {},
   "source": [
    "#### In the following section we use a pre-trained ResNet model to apply transfer learning and fine-tune it for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac28fa5",
   "metadata": {},
   "source": [
    "We first start by importing useful libraries for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d628f9e5",
   "metadata": {},
   "source": [
    "One of the best available pre-trained models for tasks similar to ours is the ResNet model. Here we use a pre-trained ResNet50 model and fine-tune it in order to solve our problem. Our dataset contains 10 classes and only the last layer will be trained and have its parameters changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained = True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(2048, 10)\n",
    "\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ca209",
   "metadata": {},
   "source": [
    "Images are resized to fit in the ResNet50 architecture, and normalized for faster computations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0337035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "data = datasets.ImageFolder('/home/josephmoussa/Desktop/content/imgs/train', transform = transforms.Compose([\n",
    "                                                                       transforms.Resize((224, 224)),\n",
    "                                                                       transforms.ToTensor(),\n",
    "                                                                       transforms.Normalize(mean, std)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06847da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = '/home/josephmoussa/Desktop/content/driver_imgs_list.csv'\n",
    "img = '/home/josephmoussa/Desktop/content/imgs/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e37760",
   "metadata": {},
   "source": [
    "In the cell below we create a dataset class, build our dataset and split it into training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68869989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, csv_to_read = csv, image_dir = img, transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                                                       transforms.ToTensor(),\n",
    "                                                                       transforms.Normalize(mean, std)]), \n",
    "                                                            target_transform = None):\n",
    "      self.img_labels = pd.read_csv(csv_to_read)\n",
    "      self.img_dir = image_dir\n",
    "      self.transform = transform\n",
    "      self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      label = self.img_labels.iloc[idx, 1]\n",
    "      img_dir_cat = self.img_dir + '/' + str(label)\n",
    "      img_path = os.path.join(img_dir_cat, self.img_labels.iloc[idx, 2])\n",
    "      image = Image.open(img_path)\n",
    "        \n",
    "      if self.transform:\n",
    "        image = self.transform(image)\n",
    "\n",
    "      if self.target_transform:\n",
    "        label = self.target_transform(label)\n",
    "\n",
    "      return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcd576",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(csv_to_read = csv, image_dir = img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e928ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_length = int(0.8 * len(data))\n",
    "val_data_length = len(data) - train_data_length\n",
    "lengths = [train_data_length, val_data_length]\n",
    "train_data, val_data = torch.utils.data.random_split(data, lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba46ee",
   "metadata": {},
   "source": [
    "The following function calculates the loss, useful for the training process. The cross-entropy loss is used, as advised by Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, dataloader_test, batch_size):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss_epoch_test = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader_test:\n",
    "            target = torch.zeros((min(len(labels), batch_size)))\n",
    "    \n",
    "            for i in range(min(len(labels), batch_size)):\n",
    "                target[i] = int(labels[i][1])\n",
    "            target = target.type(torch.cuda.LongTensor)\n",
    "            target = target.to(cuda_cpu)\n",
    "    \n",
    "            inputs = inputs.type(torch.cuda.FloatTensor)\n",
    "            inputs = inputs.to(cuda_cpu)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, target)\n",
    "            loss_epoch_test += loss\n",
    "            \n",
    "    return loss_epoch_test.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce2a9c",
   "metadata": {},
   "source": [
    "In our case we had access to a GPU, which allowed for faster computations. The success rate function is used later to measure our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_cpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def success_rate(model, val_data, batch_size):\n",
    "    N = len(val_data)\n",
    "    counter = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_data:\n",
    "            inputs = inputs.type(torch.cuda.FloatTensor)\n",
    "            inputs = inputs.to(cuda_cpu)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            target = torch.zeros((min(len(labels), batch_size)))\n",
    "            for i in range(min(len(labels), batch_size)):\n",
    "                target[i] = int(labels[i][1])\n",
    "            \n",
    "            i = 0\n",
    "            \n",
    "            for output in outputs:\n",
    "                if torch.argmax(output) == int(target[i]):\n",
    "                    counter = counter + 1\n",
    "                i = i + 1\n",
    "            l = len(target)\n",
    "          \n",
    "    rate = (counter / ((N-1) * batch_size + l)) * 100\n",
    "    \n",
    "    return rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4a886",
   "metadata": {},
   "source": [
    "With everything ready, we can now train our model, choosing the parameters giving us the best possible overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877fc0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, epochs = 5, batch_size = 200):\n",
    "    \n",
    "    model = model.cuda()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    dataloader_train = DataLoader(train_data, batch_size = batch_size, shuffle=True, num_workers=2)\n",
    "    dataloader_test = DataLoader(val_data, batch_size = batch_size, shuffle=True, num_workers=2) \n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    success_rate_ = [10]\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc = \"Total Progress: \"):\n",
    "        loss_epoch_train = 0\n",
    "        loss_epoch_test = 0\n",
    "        \n",
    "        for inputs, labels in dataloader_train:\n",
    "            target = torch.zeros((min(len(labels), batch_size)))\n",
    "    \n",
    "            for i in range(min(len(labels), batch_size)):\n",
    "                target[i] = int(labels[i][1])\n",
    "            target = target.type(torch.cuda.LongTensor)\n",
    "            target = target.to(cuda_cpu)\n",
    "    \n",
    "            inputs = inputs.type(torch.cuda.FloatTensor)\n",
    "            inputs = inputs.to(cuda_cpu)\n",
    "      \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, target)\n",
    "            loss_epoch_train += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(\"Training Loss: {0}\".format(loss_epoch_train.cpu().detach()))\n",
    "        training_loss.append(loss_epoch_train.cpu().detach())\n",
    "    \n",
    "        val_loss = calculate_loss(model, dataloader_test, batch_size)\n",
    "        print(\"Validation Loss: {0}\".format(val_loss))\n",
    "        validation_loss.append(val_loss)\n",
    "     \n",
    "        accuracy_rate = success_rate(model, dataloader_test, batch_size)\n",
    "        print(\"Model accuracy: {0} %\".format(accuracy_rate))\n",
    "        success_rate_.append(accuracy_rate)\n",
    "        \n",
    "        print(\"Epoch done.\")\n",
    "        print(\"-------------------------------------\")\n",
    "            \n",
    "    \n",
    "    plt.plot(training_loss)\n",
    "    plt.xlabel(\"Epoch number\")\n",
    "    plt.ylabel(\"Training Loss\")\n",
    "    plt.title(\"Evolution of training loss with number of epochs\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(validation_loss)\n",
    "    plt.xlabel(\"Epoch number\")\n",
    "    plt.ylabel(\"Validation Loss\")\n",
    "    plt.title(\"Evolution of validation loss with number of epochs\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(success_rate_)\n",
    "    plt.xlabel(\"Epoch number\")\n",
    "    plt.ylabel(\"Model Accuracy (%)\")\n",
    "    plt.title(\"Evolution of our model's accuracy with number of epochs\")\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7848347",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = train(model, loss_fn = nn.CrossEntropyLoss(), epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e5252",
   "metadata": {},
   "source": [
    "We can save the trained model thanks to the lines of code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82633a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = '/home/josephmoussa/Desktop/'\n",
    "file_date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "name = \"ResNet50\"\n",
    "torch.save(model.state_dict(), os.path.join(main_directory, name + file_date + '_weights_final.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e0be6",
   "metadata": {},
   "source": [
    "## Using Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded21a1",
   "metadata": {},
   "source": [
    "#### The following section can be run independently. After saving our trained model in the previous section, we will now use it and evaluate its performance on a test dataset given by Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from torchvision.io import read_image\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained = True)\n",
    "model.fc = nn.Linear(2048, 10)\n",
    "\n",
    "main_directory = '/home/josephmoussa/Desktop/'\n",
    "model.load_state_dict(torch.load(os.path.join(main_directory, 'ResNet50_20_epochs20220518_211515_weights_res.h5')))\n",
    "model.eval()\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb9f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "csv = '/home/josephmoussa/Desktop/content/driver_imgs_list.csv'\n",
    "img = '/home/josephmoussa/Desktop/content/imgs/train'\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, csv_to_read = csv, image_dir = img, transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                                                       transforms.ToTensor(),\n",
    "                                                                       transforms.Normalize(mean, std)]), \n",
    "                                                            target_transform = None):\n",
    "      self.img_labels = pd.read_csv(csv_to_read)\n",
    "      self.img_dir = image_dir\n",
    "      self.transform = transform\n",
    "      self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      label = self.img_labels.iloc[idx, 1]\n",
    "      img_dir_cat = self.img_dir + '/' + str(label)\n",
    "      img_path = os.path.join(img_dir_cat, self.img_labels.iloc[idx, 2])\n",
    "      image = Image.open(img_path)\n",
    "        \n",
    "      if self.transform:\n",
    "        image = self.transform(image)\n",
    "\n",
    "      if self.target_transform:\n",
    "        label = self.target_transform(label)\n",
    "\n",
    "      return image, label\n",
    "\n",
    "csv = '/home/josephmoussa/Desktop/content/driver_imgs_list.csv'\n",
    "img = '/home/josephmoussa/Desktop/content/imgs/train'\n",
    "data = Data(csv_to_read = csv, image_dir = img)\n",
    "\n",
    "train_data_length = int(0.8 * len(data))\n",
    "val_data_length = len(data) - train_data_length\n",
    "lengths = [train_data_length, val_data_length]\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(data, lengths)\n",
    "\n",
    "cuda_cpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ea1848",
   "metadata": {},
   "source": [
    "In the following cell we read and modify the sample submission file given by Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ec874",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"/home/josephmoussa/Desktop/content/sample_submission.csv\")\n",
    "len_sample = len(sample_submission)\n",
    "\n",
    "for i in tqdm(range(len_sample), desc = \"Total Progress: \"):\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(),\n",
    "                                   transforms.Normalize(mean, std)])\n",
    "    img = Image.open(\"/home/josephmoussa/Desktop/content/imgs/test/\" + sample_submission.img[i])\n",
    "    img = transform(img)\n",
    "    img = img.to(cuda_cpu).unsqueeze(0)\n",
    "    output = model(img)\n",
    "\n",
    "    pred = torch.nn.Softmax(dim = 1)(output).cpu().detach().numpy()[0]\n",
    "\n",
    "    for class_number in range(10):\n",
    "      sample_submission.at[i, \"c\" + str(class_number)] = pred[class_number]\n",
    "    \n",
    "    if i == 30:\n",
    "        print(sample_submission.head(30))\n",
    "\n",
    "sample_submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"/home/josephmoussa/Desktop/submission_sample_4_resnet50.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2239685",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f72f48",
   "metadata": {},
   "source": [
    "#### In the following section we plot the model's confusion matrix in order to analyze its performance according to every class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat(model, val_data, batch_size):\n",
    "    nb_classes = 10\n",
    "    confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
    "    dataloader_test = DataLoader(val_data, batch_size = batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    model = model.to(cuda_cpu)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader_test, desc = \"Total Progress: \"):\n",
    "            inputs = inputs.type(torch.cuda.FloatTensor)\n",
    "            inputs = inputs.to(cuda_cpu)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            for i in range(min(len(outputs), batch_size)):\n",
    "                pred = torch.argmax(outputs[i]).item()\n",
    "                int_label = int(labels[i][1])\n",
    "                confusion_matrix[int_label][pred] += 1\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    class_names = [\"Safe driving\", \"Texting-right\", \"Talking on the phone-right\", \n",
    "               \"Texting-left\", \"Talking on the phone-left\", \"Operating the radio\", \n",
    "               \"Drinking\", \"Reaching behind\", \"Hair and Makeup\", \n",
    "               \"Talking to passenger\"]\n",
    "    \n",
    "    df_cm = pd.DataFrame(confusion_matrix, index = class_names, columns = class_names).astype(int)\n",
    "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize = 8)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize = 8)\n",
    "\n",
    "    # Per-class accuracy\n",
    "    for i in range(nb_classes):\n",
    "        class_accuracy = 100 * confusion_matrix[i][i] / confusion_matrix[i].sum()\n",
    "        print(\"For class c{0}, the accuracy is equal to {1} %\".format(i, class_accuracy))\n",
    "        print(\"---------------------------\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beffa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(model, val_data, batch_size = 256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
